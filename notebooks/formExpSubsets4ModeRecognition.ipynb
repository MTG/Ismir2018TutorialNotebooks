{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forming data subsets for mode and rhythm mode recognition experiments\n",
    "\n",
    "This notebook targets forming data subsets for mode and rhythm mode recognition experiments starting from the list of files (and meta data info) created and stored (using generateFileLists4Collections.ipynb) in a pickle file. For each recording the following information is available:\n",
    "- Files available for that recording\n",
    "- MusicBrainz id (mbid)\n",
    "- Mode information (raga, makam, etc)\n",
    "- Rhythm mode information (tala, usul, etc)\n",
    "\n",
    "This notebook reads this file and forms the subsets by grouping recordings with respect to mode or rhythm mode while also checking available files (ex: tonic annotation) for the recording. The outputs are json files for each culture (with the format of [this sample file](https://github.com/MTG/otmm_makam_recognition_dataset/blob/master/annotations.json)) which can be used in mode recognition implementations as in [this repo](https://github.com/emirdemirel/Supervised_Mode_Recognition)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your token here from https://dunya.compmusic.upf.edu/user/profile/\n",
    "token = '...yourAPITokenGoesHere...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import codecs\n",
    "import json, os, sys\n",
    "import numpy as np\n",
    "import pickle\n",
    "import csv\n",
    "import time\n",
    "import datetime\n",
    "import random\n",
    "from compmusic.dunya import docserver as ds\n",
    "from compmusic import dunya as dn\n",
    "from compmusic.dunya import conn\n",
    "import collections\n",
    "\n",
    "dn.set_token(token)#setting the token\n",
    "\n",
    "# Read metadata from the previous notebook\n",
    "with open(\"metaData_collections.pkl\", 'rb') as f:\n",
    "    metaData = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Most frequently used modes \n",
    "Modes in each collection ordered by the number of recordings that we have for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numModes = 20\n",
    "\n",
    "for collection, recordings in metaData.items():\n",
    "    mode_counter = collections.Counter()\n",
    "    for recording in recordings:\n",
    "        if 'mode' in recording:\n",
    "            mode_counter[recording['mode']] += 1\n",
    "    print('Most frequently used modes in collection {}'.format(collection))\n",
    "    common_modes = mode_counter.most_common(numModes)\n",
    "    max_length = max([len(m) for m in dict(common_modes).keys()])\n",
    "    for mode, count in common_modes:\n",
    "        print('{mode:<{pad}} {count}'.format(mode=mode, pad=max_length, count=count))\n",
    "    print('-'*50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Composing a mode recognition datasets for all collections\n",
    "\n",
    "Creating annotations.json file for each culture that can serve as an experimental dataset. We collect the tonic frequency for a random selection of recordings in each mode. These json files can be used as input to supervised mode recognition tests in [this repo](https://github.com/emirdemirel/Supervised_Mode_Recognition) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take the top `numModes` modes. Randomly select recordings of this mode from the collection\n",
    "# until we have at least `numFilesPerMode` downloads for each mode.\n",
    "\n",
    "def download_tonic(mbid, collection):\n",
    "    \"\"\"Retrieve the tonic value for a given recording\n",
    "    \n",
    "    Arguments:\n",
    "        mbid: the recording MBID to retrieve\n",
    "        collection: the name of the collection that this MBID comes from\n",
    "                    (used to choose the download method)\n",
    "                    \n",
    "    Returns: The tonic of the recording, or None of this recording has no tonic computed\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if collection == 'makam': \n",
    "            content = ds.get_document_as_json(mbid, 'audioanalysis', 'tonic')\n",
    "            tonic = None\n",
    "            if content:\n",
    "                tonic = content['value']\n",
    "        elif collection == 'carnatic' or collection == 'hindustani':\n",
    "            content = ds.file_for_document(recording['mbid'], 'ctonic', 'tonic')\n",
    "            tonic = content.decode()\n",
    "        return tonic\n",
    "    except dn.HTTPError as e:\n",
    "        if e.args[0].response.status_code != 404:\n",
    "            raise\n",
    "\n",
    "def get_tonics_for_recordings(recordings, collection, numModes, numFilesPerMode):\n",
    "    # Count the modes in the recording list and group recordings by their mode\n",
    "    mode_counter = collections.Counter()\n",
    "    mode_recordings = collections.defaultdict(list)\n",
    "    for recording in recordings:\n",
    "        if 'mode' in recording:\n",
    "            mode_counter[recording['mode']] += 1\n",
    "            mode_recordings[recording['mode']].append(recording)\n",
    "    selected_modes = dict(mode_counter.most_common(numModes)).keys()\n",
    "    # for each mode, download tonic for `numFilesPerMode` random recordings\n",
    "    collection_sample = []\n",
    "    for mode in selected_modes:\n",
    "        recordings = mode_recordings[mode]\n",
    "        num_recordings = 0\n",
    "        for recording in recordings:\n",
    "            if num_recordings >= numFilesPerMode:\n",
    "                break\n",
    "            tonic = download_tonic(recording['mbid'], collection)\n",
    "            # Some recordings may not have a tonic, only add those for which we do\n",
    "            if tonic:\n",
    "                recording['tonic'] = tonic\n",
    "                collection_sample.append(recording)\n",
    "                num_recordings += 1\n",
    "    return collection_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numModes = 10\n",
    "numFilesPerMode = 20\n",
    "\n",
    "tonics = {}\n",
    "\n",
    "for collection, recordings in metaData.items():\n",
    "    print('Downloading Tonic values for collection {}'.format(collection))\n",
    "    \n",
    "    collection_sample = get_tonics_for_recordings(recordings, collection, numModes, numFilesPerMode)\n",
    "\n",
    "    tonics[collection] = collection_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Write tonic data to file\n",
    "for collection, recordings in tonics.items():\n",
    "    with open('annotations_{}.json'.format(collection), 'w') as f:\n",
    "        json.dump(recordings, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
