{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning analysis for a set of recordings from the same mode\n",
    "\n",
    "Here, we demonstrate tuning analysis of a set of recordings in several modes. The names of the modes and number of files used in each mode is set in the second code cell. \n",
    "The following steps are carried:\n",
    "- A group of recordings from the set of files listed in the [annotations.json file](https://github.com/MTG/otmm_makam_recognition_dataset ) in the given modes are downloaded as the first step.\n",
    "- Then pitch analysis and pitch distribution computation is carried\n",
    "- Tonic annotation is accessed from Dunya and interval distributions are computed (with respect to tonic)\n",
    "- Octave folding is applied and mean of all distributions are computed\n",
    "- Automatic peak picking applied to detect scale degrees' distance to the tonic\n",
    "- Interval list stored in the Scala format (http://www.huygens-fokker.org/scala/) to be able to sonify the intervals using computer keyboard. A Scala file(.scl) is created for each mode in the modes list. \n",
    "\n",
    "To be able to download sounds from Dunya, you would need to create a user and obtain an API authenticaion key(token). Please create your user from: https://dunya.compmusic.upf.edu/developers/ In order to get your API token you have to log in to Dunya, access your profile, you will find your token there. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your token here from https://dunya.compmusic.upf.edu/user/profile/\n",
    "token = '...yourAPITokenGoesHere...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "from compmusic.dunya import docserver as ds\n",
    "from compmusic import dunya as dn\n",
    "from external_utilities.predominantmelodymakam import PredominantMelodyMakam\n",
    "from external_utilities.pitchdistribution import PitchDistribution\n",
    "from scipy.spatial import distance\n",
    "\n",
    "from compmusic import dunya\n",
    "dn.set_token(token)\n",
    "\n",
    "%matplotlib inline\n",
    "CENTS_IN_OCTAVE = 1200\n",
    "REF_PITCH = 220"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Downloading the recordings with mode 'Huseyni'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading mp3 files in ../data/compMusicDatasets/turkishMakam\n",
      "15 files downloaded\n",
      "15 files downloaded\n",
      "15 files downloaded\n",
      "Download finished!\n"
     ]
    }
   ],
   "source": [
    "fileType = 'mp3'\n",
    "numFiles = 15\n",
    "collectionName = 'makam'\n",
    "modeType = 'makam'\n",
    "# modes for which we will estimate a scale\n",
    "modes = ['Huseyni', 'Saba', 'Huzzam']\n",
    "dataDir = os.path.join('..', 'data', 'compMusicDatasets', 'turkishMakam')\n",
    "\n",
    "# Load dataset files in mode Huseyni\n",
    "with open(os.path.join(dataDir, 'annotations.json')) as json_data:\n",
    "    collectionFiles = json.load(json_data)\n",
    "\n",
    "#Create directories for modes and download one recording for each\n",
    "modeFilesInfo = {}\n",
    "print('Downloading mp3 files in {}'.format(dataDir))\n",
    "for mode in modes:\n",
    "    os.makedirs(os.path.join(dataDir, mode), exist_ok=True)\n",
    "\n",
    "    mbidList = []\n",
    "    tonics = {}\n",
    "    fileCnt = 0\n",
    "    for file in collectionFiles:\n",
    "        if file[modeType] == mode:\n",
    "            mbid = file['mbid'].split('http://musicbrainz.org/recording/')[-1]\n",
    "            try:\n",
    "                content = ds.get_document_as_json(mbid, 'audioanalysis', 'tonic')\n",
    "                tonic = content['value']\n",
    "            except dunya.HTTPError:\n",
    "                tonic = None\n",
    "            \n",
    "            # If tonic info is available from Dunya, add to set of recordings\n",
    "            if not tonic:\n",
    "                print('Tonic could not be read for {}, skipping this file'.format(mbid))\n",
    "            else:\n",
    "                tonics[mbid] = float(tonic)\n",
    "                mbidList.append(mbid)\n",
    "          \n",
    "                #Download mp3\n",
    "                name = '{}.{}'.format(mbid, fileType)\n",
    "                mp3FileURI = os.path.join(dataDir, mode, name)\n",
    "                # Download file if it has not been previously downloaded\n",
    "                if not os.path.exists(mp3FileURI):\n",
    "                    contents = ds.file_for_document(mbid, fileType)\n",
    "                    open(mp3FileURI, \"wb\").write(contents)\n",
    "                fileCnt += 1\n",
    "                if fileCnt >= numFiles:\n",
    "                    print('{} files downloaded'.format(numFiles))\n",
    "                    break\n",
    "    modeFilesInfo[mode] = (mbidList, tonics)\n",
    "    \n",
    "print('Download finished!')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pitch extraction and distribution computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tonic_aligned_octave_wrapped_dist(mode, mbidList, tonics, pd_params, numBins, dataDir):\n",
    "    '''Gathering tonic aligned octave wrapped distributions \n",
    "    \n",
    "    Args:\n",
    "        mode (str): name of the mode ('Huseyni', 'Saba', etc)\n",
    "        mbidList (list): list of musicbrainz ids\n",
    "        tonics (dict): dictionary mapping mbids to tonic info in Hz\n",
    "        numBins (int): number of bins in octave for the distribution\n",
    "        dataDir (str): path info\n",
    "    Outputs:\n",
    "        pcds (numpy array(2D)): 2D array(pd size * number of file) \n",
    "            containing pitch distribution for each file   \n",
    "    '''\n",
    "    pcds = np.array([]).reshape(0,numBins)\n",
    "    #Pitch extractor definition\n",
    "    extractor = PredominantMelodyMakam(filter_pitch=True)\n",
    "    print('Pitch analysis of files in mode ', mode)\n",
    "\n",
    "    for mbid in mbidList:\n",
    "        name = '{}.{}'.format(mbid, fileType)\n",
    "        mp3FileURI = os.path.join(dataDir, mode,name)\n",
    "        #Setting file names for writing analysis results\n",
    "        pitchFile = os.path.join(dataDir, mode, '{}.pitch'.format(mbid))\n",
    "        histFile = os.path.join(dataDir, mode, '{}.pitch_hist.json'.format(mbid))\n",
    "\n",
    "        #If pitch file exists, read it, if not run extractor and create the pitch file\n",
    "        if not os.path.exists(pitchFile):\n",
    "            #running pitch extraction \n",
    "            results = extractor.run(mp3FileURI)\n",
    "            pitch = results['settings']  # collapse the keys in settings\n",
    "            pitch['pitch'] = results['pitch']\n",
    "            # Write pitch data to text file, \n",
    "            # you can use it together with SonicVisualizer to view in sync with the spectrogram of the mp3 file\n",
    "            pitchSeriesHz = []\n",
    "            file = open(pitchFile,'w')\n",
    "            for p_triplet in pitch['pitch']:\n",
    "                file.write(str(p_triplet[0])+'\\t'+str(p_triplet[1])+'\\n')\n",
    "                pitchSeriesHz.append(p_triplet[1])\n",
    "            file.close()\n",
    "            pitchSeriesHz = np.array(pitchSeriesHz)\n",
    "        else:\n",
    "            pitchData = np.loadtxt(pitchFile)\n",
    "            timeStamps = pitchData[:,0]\n",
    "            pitchSeriesHz = pitchData[:,1]\n",
    "\n",
    "        #Pitch distribution computation\n",
    "        #Computing pitch distribution with default reference frequency = REF_PITCH\n",
    "        pitch_distribution = PitchDistribution.from_hz_pitch(pitchSeriesHz,REF_PITCH, **pd_params)\n",
    "        pitch_distribution.to_json(histFile)\n",
    "\n",
    "        #Computing pitch distribution with reference frequency = tonic\n",
    "        tonic_Hz = tonics[mbid]\n",
    "        pitch_distribution_tonicRef = PitchDistribution.from_hz_pitch(pitchSeriesHz,tonic_Hz, **pd_params)\n",
    "        pitch_distribution_tonicRef.to_json(histFile.replace('.pitch_hist.json','.pitch_hist_wrtTonic.json'))\n",
    "\n",
    "        #Creating octave folded distribution\n",
    "        pcd = np.zeros(numBins)#initializing pitch class distribution\n",
    "        for index_pd in range(len(pitch_distribution_tonicRef.bins)):\n",
    "            bin_pd = pitch_distribution_tonicRef.bins[index_pd] #get bin in pitch distribution\n",
    "            index_pcd = int(np.mod(bin_pd,CENTS_IN_OCTAVE)/pd_params['step_size']) #corresponding index in pitch class distribution\n",
    "            pcd[index_pcd] += pitch_distribution_tonicRef.vals[index_pd]\n",
    "        pcds = np.vstack((pcds,pcd))\n",
    "\n",
    "    return pcds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pitch analysis of files in mode  Huseyni\n",
      "Pitch analysis of files in mode  Saba\n",
      "Pitch analysis of files in mode  Huzzam\n",
      "Pitch files are stored in ../data/compMusicDatasets/turkishMakam\n",
      "You can use Sonic Visualizer at this step to check pitch extraction quality\n"
     ]
    }
   ],
   "source": [
    "# Running extraction and gathering of data\n",
    "# pitch distribution extractor parameters in cents\n",
    "pd_params = {'kernel_width': 5, 'step_size': 5}\n",
    "# distribution bins for octave-folded histogram\n",
    "bins = np.linspace(0, CENTS_IN_OCTAVE, CENTS_IN_OCTAVE/pd_params['step_size'], endpoint=False)\n",
    "numBins = len(bins)\n",
    "\n",
    "# Gathering tonic aligned, octave wrapped distributions for each mode\n",
    "modePcds = {}\n",
    "for mode in modes:\n",
    "    mbidList, tonics = modeFilesInfo[mode]\n",
    "    pcds = tonic_aligned_octave_wrapped_dist(mode, mbidList, tonics, pd_params, numBins, dataDir)\n",
    "    modePcds[mode] = pcds\n",
    "\n",
    "print('Pitch files are stored in {}'.format(dataDir))\n",
    "print('You can use Sonic Visualizer at this step to check pitch extraction quality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plotting all distributions\n",
    "for mode in modes:\n",
    "    pcds = modePcds[mode]\n",
    "    plt.figure(figsize=(13, 3))\n",
    "    for pcd in pcds:\n",
    "        plt.plot(bins,pcd)\n",
    "\n",
    "    plt.title('Octave folded pitch distributions for '+str(len(pcds))+' files in mode '+mode)\n",
    "    plt.xlim([0,1200])\n",
    "    plt.grid()\n",
    "    ticks = np.arange(0,1200,100)\n",
    "    plt.vlines(ticks, 0, np.max(pcds), color='y',lw=1)\n",
    "    plt.ylabel('Relative freq. of occurence')\n",
    "    plt.xlabel('Distance to tonic(cents)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plotting average distribution and extracting scale information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Function definition for automatic scale-interval detection from pitch distribution\n",
    "def peakLocationDetection(pcd):\n",
    "    '''A simple peak detection implementation for demonstration purposes\n",
    "    Thresholds are manually set for this demo\n",
    "    '''\n",
    "    windowSize=15#should be odd\n",
    "    midPointIndex=int(windowSize/2)\n",
    "    threshold=np.max(pcd)*0.05\n",
    "    peakIndexes=[]\n",
    "    for index in range(len(pcd)-windowSize):\n",
    "        frame=pcd[index:index+windowSize]\n",
    "        if (np.argmax(frame)==midPointIndex) and np.max(frame)>threshold:\n",
    "            peakIndexes.append(index+midPointIndex)\n",
    "    return peakIndexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extracting intervals and plotting together with mean distributions\n",
    "modeIntervals = {}\n",
    "for mode in modes:\n",
    "    pcds = modePcds[mode]\n",
    "    \n",
    "    pcds_array = np.array(pcds)\n",
    "    mean_pcd = np.mean(pcds, axis=0)\n",
    "\n",
    "    plt.figure(figsize=(13, 3))\n",
    "    ticks = np.arange(0,1200,100)\n",
    "    plt.vlines(ticks, 0, max(mean_pcd), color='y', lw=1)\n",
    "    plt.plot(bins,mean_pcd)\n",
    "\n",
    "    plt.title('Octave folded mean pitch distribution for mode {}'.format(mode))\n",
    "    plt.xlim([0,1200])\n",
    "    plt.grid()\n",
    "    plt.ylabel('Relative freq. of occurence')\n",
    "    plt.xlabel('Distance to tonic(cents)')\n",
    "\n",
    "    # Detect intervals from pitch distribution and plot them on the figure\n",
    "    intervals = np.array(peakLocationDetection(mean_pcd))*pd_params['step_size']\n",
    "    plt.vlines(intervals, 0, max(mean_pcd), color='r', lw=2)\n",
    "    print('Intervals computed: {} (cents with respect to tonic)'.format(intervals))\n",
    "    modeIntervals[mode] = intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Scala file\n",
    "Writing the scale to .scl file which can be loaded in Scala with which one can sonify the estimated scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for mode in modes:\n",
    "    intervals=modeIntervals[mode]\n",
    "    scalaFile=dataDir+mode+'_scale.scl'\n",
    "    file = open(scalaFile,'w')\n",
    "    file.write('! autopeak.scl\\n!\\nFile created by tuningAnalysis\\n'+str(len(intervals)+1)+'\\n!\\n')\n",
    "    #First octave\n",
    "    for interval in intervals:\n",
    "        file.write(str(float(interval))+'\\n')\n",
    "    file.write(str(float(CENTS_IN_OCTAVE))+'\\n')#octave\n",
    "    file.close()\n",
    "\n",
    "\"\"\"\n",
    "scalaFile = os.path.join(dataDir, '{}_scale.scl'.format(mode))\n",
    "with open(scalaFile, 'w') as fp:\n",
    "    fp.write('! autopeak.scl\\n!\\nFile created by tuningAnalysis\\n'+str(len(intervals)+1)+'\\n!\\n')\n",
    "\n",
    "    #First octave\n",
    "    for interval in intervals:\n",
    "        fp.write(str(float(interval))+'\\n')\n",
    "    fp.write(str(float(CENTS_IN_OCTAVE))+'\\n')#octave\n",
    "    fp.close()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the estimated scales in Scala\n",
    "Initiate a synthesizer your Scala software can communicate with for synthesis (for example simplesynth). Open Scala and click 'Open' to choose the .scl file this code has created in your local folder: 'mode'_scale.scl. A scl file is created for each mode.\n",
    "\n",
    "Scala would display the set of pitches of the loaded scale as a list and set the keyboard layout to start the scale with C. If you would like to set tonic to some other note and frequency, click 'Opts.' on the top menu. You can set the tonic frequency('frequency for 1/1') and the offset (deafult is C.0)\n",
    "\n",
    "Now you can click 'Play' on the top menu to start experiment with your new keyboard playing the scale automatically extracted by the analysis above. Enjoy!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
